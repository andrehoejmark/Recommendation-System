{"nbformat":4,"nbformat_minor":5,"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"colab":{"name":"movie-recommendation.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"bb412de9"},"source":["import pandas as pd\n","from sklearn import model_selection, metrics, preprocessing\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np"],"id":"bb412de9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0f4e6899"},"source":["# here is a handy function modified from fast.ai\n","def proc_col(col, train_col=None):\n","    \"\"\"Encodes a pandas column with continous ids. \n","    \"\"\"\n","    if train_col is not None:\n","        uniq = train_col.unique()\n","    else:\n","        uniq = col.unique()\n","    name2idx = {o:i for i,o in enumerate(uniq)}\n","    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"],"id":"0f4e6899","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dafa5a5"},"source":["def encode_data(df, train=None):\n","    \"\"\" Encodes rating data with continous user and movie ids. \n","    If train is provided, encodes df with the same encoding as train.\n","    \"\"\"\n","    df = df.copy()\n","    for col_name in [\"user_id\", \"item_id\"]:\n","        train_col = None\n","        if train is not None:\n","            train_col = train[col_name]\n","        _,col,_ = proc_col(df[col_name], train_col)\n","        df[col_name] = col\n","        df = df[df[col_name] >= 0]\n","    return df"],"id":"1dafa5a5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ac4a339c"},"source":["header = ['user_id', 'item_id', 'rating', 'timestamp']\n","df = pd.read_csv('ml-100k/u.data', sep='\\t', names=header)"],"id":"ac4a339c","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5d384e49"},"source":["train, val = model_selection.train_test_split(df, test_size=0.1, random_state=4, stratify=df.rating.values)"],"id":"5d384e49","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5409e53e"},"source":["df_train = encode_data(train)\n","df_val = encode_data(train, val)"],"id":"5409e53e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20ca2b71","outputId":"c0a7da26-0d22-4eee-e493-b42114d6f767"},"source":["df_train[0:50]"],"id":"20ca2b71","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>53270</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>888519206</td>\n","    </tr>\n","    <tr>\n","      <th>76926</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>881605093</td>\n","    </tr>\n","    <tr>\n","      <th>86402</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>891447157</td>\n","    </tr>\n","    <tr>\n","      <th>42887</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>885807173</td>\n","    </tr>\n","    <tr>\n","      <th>72708</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>882814571</td>\n","    </tr>\n","    <tr>\n","      <th>26958</th>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>883876573</td>\n","    </tr>\n","    <tr>\n","      <th>13925</th>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>887249889</td>\n","    </tr>\n","    <tr>\n","      <th>25588</th>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>875154535</td>\n","    </tr>\n","    <tr>\n","      <th>24946</th>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>884496985</td>\n","    </tr>\n","    <tr>\n","      <th>98732</th>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>3</td>\n","      <td>891353801</td>\n","    </tr>\n","    <tr>\n","      <th>79378</th>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>3</td>\n","      <td>880584584</td>\n","    </tr>\n","    <tr>\n","      <th>35780</th>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>883789635</td>\n","    </tr>\n","    <tr>\n","      <th>1361</th>\n","      <td>12</td>\n","      <td>12</td>\n","      <td>4</td>\n","      <td>880564570</td>\n","    </tr>\n","    <tr>\n","      <th>22383</th>\n","      <td>13</td>\n","      <td>13</td>\n","      <td>4</td>\n","      <td>891888178</td>\n","    </tr>\n","    <tr>\n","      <th>59328</th>\n","      <td>14</td>\n","      <td>14</td>\n","      <td>4</td>\n","      <td>888260089</td>\n","    </tr>\n","    <tr>\n","      <th>74586</th>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>2</td>\n","      <td>882385934</td>\n","    </tr>\n","    <tr>\n","      <th>63788</th>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>5</td>\n","      <td>876267235</td>\n","    </tr>\n","    <tr>\n","      <th>7903</th>\n","      <td>17</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>884748978</td>\n","    </tr>\n","    <tr>\n","      <th>93271</th>\n","      <td>18</td>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>876347040</td>\n","    </tr>\n","    <tr>\n","      <th>859</th>\n","      <td>19</td>\n","      <td>19</td>\n","      <td>5</td>\n","      <td>892836309</td>\n","    </tr>\n","    <tr>\n","      <th>26691</th>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>5</td>\n","      <td>893213444</td>\n","    </tr>\n","    <tr>\n","      <th>76564</th>\n","      <td>21</td>\n","      <td>21</td>\n","      <td>3</td>\n","      <td>889909812</td>\n","    </tr>\n","    <tr>\n","      <th>86451</th>\n","      <td>22</td>\n","      <td>22</td>\n","      <td>2</td>\n","      <td>885546577</td>\n","    </tr>\n","    <tr>\n","      <th>71698</th>\n","      <td>23</td>\n","      <td>23</td>\n","      <td>4</td>\n","      <td>891217340</td>\n","    </tr>\n","    <tr>\n","      <th>41550</th>\n","      <td>24</td>\n","      <td>24</td>\n","      <td>4</td>\n","      <td>885478374</td>\n","    </tr>\n","    <tr>\n","      <th>8528</th>\n","      <td>25</td>\n","      <td>25</td>\n","      <td>3</td>\n","      <td>875509262</td>\n","    </tr>\n","    <tr>\n","      <th>41216</th>\n","      <td>26</td>\n","      <td>26</td>\n","      <td>4</td>\n","      <td>880139090</td>\n","    </tr>\n","    <tr>\n","      <th>68428</th>\n","      <td>27</td>\n","      <td>27</td>\n","      <td>4</td>\n","      <td>879796010</td>\n","    </tr>\n","    <tr>\n","      <th>91968</th>\n","      <td>28</td>\n","      <td>28</td>\n","      <td>3</td>\n","      <td>886367474</td>\n","    </tr>\n","    <tr>\n","      <th>43002</th>\n","      <td>29</td>\n","      <td>29</td>\n","      <td>4</td>\n","      <td>879191972</td>\n","    </tr>\n","    <tr>\n","      <th>19245</th>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>1</td>\n","      <td>880937070</td>\n","    </tr>\n","    <tr>\n","      <th>62353</th>\n","      <td>31</td>\n","      <td>31</td>\n","      <td>4</td>\n","      <td>876538627</td>\n","    </tr>\n","    <tr>\n","      <th>42155</th>\n","      <td>32</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>891372286</td>\n","    </tr>\n","    <tr>\n","      <th>86235</th>\n","      <td>33</td>\n","      <td>33</td>\n","      <td>3</td>\n","      <td>875914785</td>\n","    </tr>\n","    <tr>\n","      <th>24351</th>\n","      <td>34</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>882480710</td>\n","    </tr>\n","    <tr>\n","      <th>7759</th>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>5</td>\n","      <td>892679144</td>\n","    </tr>\n","    <tr>\n","      <th>51735</th>\n","      <td>36</td>\n","      <td>36</td>\n","      <td>5</td>\n","      <td>891446588</td>\n","    </tr>\n","    <tr>\n","      <th>59769</th>\n","      <td>37</td>\n","      <td>37</td>\n","      <td>5</td>\n","      <td>891279122</td>\n","    </tr>\n","    <tr>\n","      <th>24754</th>\n","      <td>38</td>\n","      <td>38</td>\n","      <td>1</td>\n","      <td>888067765</td>\n","    </tr>\n","    <tr>\n","      <th>4711</th>\n","      <td>39</td>\n","      <td>39</td>\n","      <td>2</td>\n","      <td>891374603</td>\n","    </tr>\n","    <tr>\n","      <th>55622</th>\n","      <td>40</td>\n","      <td>40</td>\n","      <td>4</td>\n","      <td>881695560</td>\n","    </tr>\n","    <tr>\n","      <th>48666</th>\n","      <td>41</td>\n","      <td>41</td>\n","      <td>4</td>\n","      <td>882922204</td>\n","    </tr>\n","    <tr>\n","      <th>24434</th>\n","      <td>42</td>\n","      <td>42</td>\n","      <td>3</td>\n","      <td>875319786</td>\n","    </tr>\n","    <tr>\n","      <th>1894</th>\n","      <td>43</td>\n","      <td>43</td>\n","      <td>4</td>\n","      <td>879572403</td>\n","    </tr>\n","    <tr>\n","      <th>40523</th>\n","      <td>44</td>\n","      <td>44</td>\n","      <td>2</td>\n","      <td>884882527</td>\n","    </tr>\n","    <tr>\n","      <th>86170</th>\n","      <td>19</td>\n","      <td>45</td>\n","      <td>5</td>\n","      <td>879454628</td>\n","    </tr>\n","    <tr>\n","      <th>51614</th>\n","      <td>45</td>\n","      <td>46</td>\n","      <td>3</td>\n","      <td>878847716</td>\n","    </tr>\n","    <tr>\n","      <th>59578</th>\n","      <td>46</td>\n","      <td>47</td>\n","      <td>3</td>\n","      <td>893286346</td>\n","    </tr>\n","    <tr>\n","      <th>11544</th>\n","      <td>47</td>\n","      <td>48</td>\n","      <td>2</td>\n","      <td>879877349</td>\n","    </tr>\n","    <tr>\n","      <th>1700</th>\n","      <td>48</td>\n","      <td>49</td>\n","      <td>2</td>\n","      <td>891181430</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       user_id  item_id  rating  timestamp\n","53270        0        0       5  888519206\n","76926        1        1       3  881605093\n","86402        2        2       5  891447157\n","42887        3        3       3  885807173\n","72708        4        4       5  882814571\n","26958        5        5       2  883876573\n","13925        6        6       2  887249889\n","25588        7        7       3  875154535\n","24946        8        8       4  884496985\n","98732        9        9       3  891353801\n","79378       10       10       3  880584584\n","35780       11       11       4  883789635\n","1361        12       12       4  880564570\n","22383       13       13       4  891888178\n","59328       14       14       4  888260089\n","74586       15       15       2  882385934\n","63788       16       16       5  876267235\n","7903        17       17       4  884748978\n","93271       18       18       1  876347040\n","859         19       19       5  892836309\n","26691       20       20       5  893213444\n","76564       21       21       3  889909812\n","86451       22       22       2  885546577\n","71698       23       23       4  891217340\n","41550       24       24       4  885478374\n","8528        25       25       3  875509262\n","41216       26       26       4  880139090\n","68428       27       27       4  879796010\n","91968       28       28       3  886367474\n","43002       29       29       4  879191972\n","19245       30       30       1  880937070\n","62353       31       31       4  876538627\n","42155       32       32       4  891372286\n","86235       33       33       3  875914785\n","24351       34       34       3  882480710\n","7759        35       35       5  892679144\n","51735       36       36       5  891446588\n","59769       37       37       5  891279122\n","24754       38       38       1  888067765\n","4711        39       39       2  891374603\n","55622       40       40       4  881695560\n","48666       41       41       4  882922204\n","24434       42       42       3  875319786\n","1894        43       43       4  879572403\n","40523       44       44       2  884882527\n","86170       19       45       5  879454628\n","51614       45       46       3  878847716\n","59578       46       47       3  893286346\n","11544       47       48       2  879877349\n","1700        48       49       2  891181430"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"code_folding":[],"id":"1bce6b99"},"source":["class net(nn.Module):\n","    def __init__(self, num_users, num_movies):\n","        super(net, self).__init__()\n","        \n","        self.user_embed = nn.Embedding(num_users, 32)\n","        self.movie_embed = nn.Embedding(num_movies, 32)\n","        self.out = nn.Linear(64, 1)\n","        \n","    def forward(self, users, movies):\n","        user_embeds = self.user_embed(users)\n","        movie_embeds = self.movie_embed(movies)\n","        \n","        #print(user_embeds, user_embeds.shape)\n","        #print(movie_embeds, movie_embeds.shape)\n","        \n","        output = torch.cat([user_embeds, movie_embeds], dim=1)\n","\n","        #output = torch.cat([torch.reshape(user_embeds, (1, len(user_embeds))), torch.reshape(movie_embeds, (1, len(movie_embeds)))], dim=1)\n","        \n","        output = self.out(output)\n","\n","        return output\n","\n","class MF(nn.Module):\n","    def __init__(self, num_users, num_items, emb_size=100):\n","        super(MF, self).__init__()\n","        self.user_emb = nn.Embedding(num_users, 100)\n","        self.item_emb = nn.Embedding(num_items, 100)\n","        self.user_emb.weight.data.uniform_(0, 0.05)\n","        self.item_emb.weight.data.uniform_(0, 0.05)\n","    \n","    def forward(self, u, v):\n","        u = self.user_emb(u)\n","        v = self.item_emb(v)\n","        return (u*v).sum(1)"],"id":"1bce6b99","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ac4b863"},"source":["num_unique_users = len(set(df_train.user_id.values))\n","num_unique_movies = len(set(df_train.item_id.values))"],"id":"1ac4b863","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"04b085fc"},"source":["model = MF(num_unique_users, num_unique_movies)"],"id":"04b085fc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cdf46cc"},"source":["opt = torch.optim.Adam(model.parameters(), lr=1e-3)"],"id":"5cdf46cc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7aad9f5"},"source":["loss_function = nn.MSELoss(reduction='none')"],"id":"b7aad9f5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1fd63de7"},"source":["def test_loss(model, unsqueeze=False):\n","    model.eval()\n","    users = torch.LongTensor(df_val.user_id.values) #.cuda()\n","    items = torch.LongTensor(df_val.item_id.values) #.cuda()\n","    ratings = torch.FloatTensor(df_val.rating.values) #.cuda()\n","\n","    y_hat = model(users, items)\n","    \n","    count = 0\n","    for i in range(len(y_hat)):\n","        \n","        diff = np.abs(y_hat[i].detach().numpy() - ratings[i].detach().numpy())\n","        #print(\"diff: \", diff)\n","        if round(diff) == 0 or round(diff) == 1:\n","            count += 1\n","    print(\"Accuracy: \", count / len(y_hat))\n","\n","    loss = F.mse_loss(y_hat, ratings)\n","    print(\"test loss %.3f \" % loss.item())"],"id":"1fd63de7","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71b4fad1"},"source":["def train_epocs(model, epochs=10, lr=0.01, wd=0.0):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n","    model.train()\n","    for i in range(epochs):\n","        users = torch.LongTensor(df_train.user_id.values)\n","        items = torch.LongTensor(df_train.item_id.values)\n","        ratings = torch.FloatTensor(df_train.rating.values) \n","        \n","        y_hat = model(users, items)\n","        print(\"y_hat:\", y_hat, y_hat.shape)\n","        loss = F.mse_loss(y_hat, ratings)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        print(loss.item())\n","    test_loss(model, unsqueeze)"],"id":"71b4fad1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcd2c8d2","outputId":"3454ac7f-5c45-4590-f11d-c735a361c1a2"},"source":["train_epocs(model, epochs=15, lr=0.01)"],"id":"dcd2c8d2","execution_count":null,"outputs":[{"output_type":"stream","text":["new\n","torch.Size([90000, 100])\n","tensor([3.4546, 3.8965, 3.8118,  ..., 2.8735, 4.5192, 3.5110],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.4546, 3.8965, 3.8118,  ..., 2.8735, 4.5192, 3.5110],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8639264702796936\n","new\n","torch.Size([90000, 100])\n","tensor([3.8367, 4.2528, 4.2126,  ..., 2.8541, 4.1034, 3.8985],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.8367, 4.2528, 4.2126,  ..., 2.8541, 4.1034, 3.8985],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8554012179374695\n","new\n","torch.Size([90000, 100])\n","tensor([3.6990, 4.0487, 4.1684,  ..., 2.7618, 4.0058, 3.9359],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.6990, 4.0487, 4.1684,  ..., 2.7618, 4.0058, 3.9359],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.84673672914505\n","new\n","torch.Size([90000, 100])\n","tensor([3.5183, 3.8249, 4.0350,  ..., 2.7745, 4.1310, 3.8424],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.5183, 3.8249, 4.0350,  ..., 2.7745, 4.1310, 3.8424],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8409619927406311\n","new\n","torch.Size([90000, 100])\n","tensor([3.4172, 3.7160, 3.9399,  ..., 2.8392, 4.3073, 3.7269],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.4172, 3.7160, 3.9399,  ..., 2.8392, 4.3073, 3.7269],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8403017520904541\n","new\n","torch.Size([90000, 100])\n","tensor([3.4077, 3.7255, 3.9251,  ..., 2.8839, 4.4095, 3.6535],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.4077, 3.7255, 3.9251,  ..., 2.8839, 4.4095, 3.6535],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8377571105957031\n","new\n","torch.Size([90000, 100])\n","tensor([3.4567, 3.8070, 3.9680,  ..., 2.8867, 4.3872, 3.6407],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.4567, 3.8070, 3.9680,  ..., 2.8867, 4.3872, 3.6407],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8324915766716003\n","new\n","torch.Size([90000, 100])\n","tensor([3.5280, 3.9125, 4.0284,  ..., 2.8453, 4.2864, 3.6743],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.5280, 3.9125, 4.0284,  ..., 2.8453, 4.2864, 3.6743],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.82752525806427\n","new\n","torch.Size([90000, 100])\n","tensor([3.5899, 3.9980, 4.0711,  ..., 2.7883, 4.1675, 3.7294],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.5899, 3.9980, 4.0711,  ..., 2.7883, 4.1675, 3.7294],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8243083357810974\n","new\n","torch.Size([90000, 100])\n","tensor([3.6240, 4.0366, 4.0798,  ..., 2.7397, 4.0887, 3.7810],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.6240, 4.0366, 4.0798,  ..., 2.7397, 4.0887, 3.7810],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8212300539016724\n","new\n","torch.Size([90000, 100])\n","tensor([3.6285, 4.0261, 4.0598,  ..., 2.7084, 4.0805, 3.8125],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.6285, 4.0261, 4.0598,  ..., 2.7084, 4.0805, 3.8125],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8166632652282715\n","new\n","torch.Size([90000, 100])\n","tensor([3.6123, 3.9812, 4.0286,  ..., 2.6942, 4.1353, 3.8204],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.6123, 3.9812, 4.0286,  ..., 2.6942, 4.1353, 3.8204],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8108847141265869\n","new\n","torch.Size([90000, 100])\n","tensor([3.5871, 3.9236, 4.0044,  ..., 2.6888, 4.2255, 3.8124],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.5871, 3.9236, 4.0044,  ..., 2.6888, 4.2255, 3.8124],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.8049810528755188\n","new\n","torch.Size([90000, 100])\n","tensor([3.5627, 3.8745, 3.9973,  ..., 2.6808, 4.3152, 3.8009],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.5627, 3.8745, 3.9973,  ..., 2.6808, 4.3152, 3.8009],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.799283504486084\n","new\n","torch.Size([90000, 100])\n","tensor([3.5449, 3.8479, 4.0064,  ..., 2.6627, 4.3703, 3.7979],\n","       grad_fn=<SumBackward1>)\n","\n","y_hat: tensor([3.5449, 3.8479, 4.0064,  ..., 2.6627, 4.3703, 3.7979],\n","       grad_fn=<SumBackward1>) torch.Size([90000])\n","0.7930821180343628\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'unsqueeze' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-34-b49f1bc3152d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_epocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m<ipython-input-33-83adf8a5390e>\u001b[0m in \u001b[0;36mtrain_epocs\u001b[1;34m(model, epochs, lr, wd)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsqueeze\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mNameError\u001b[0m: name 'unsqueeze' is not defined"]}]},{"cell_type":"code","metadata":{"id":"0305eafd"},"source":[""],"id":"0305eafd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fe7684f0"},"source":[""],"id":"fe7684f0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"df101480"},"source":[""],"id":"df101480","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d05fdcd0"},"source":[""],"id":"d05fdcd0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fc6e4ea9"},"source":[""],"id":"fc6e4ea9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5da572a5"},"source":[""],"id":"5da572a5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1eb862b1"},"source":[""],"id":"1eb862b1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10ca06c3"},"source":[""],"id":"10ca06c3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"07940abe"},"source":[""],"id":"07940abe","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4b80615c"},"source":[""],"id":"4b80615c","execution_count":null,"outputs":[]}]}